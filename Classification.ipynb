{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3c5bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a169150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import sqrt, pi , exp\n",
    "from csv import reader\n",
    "from random import seed, randrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e58266",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Describe the process: distances, error function, total loss, gradient descent, etc.; as needed\n",
    "* Debug and solve any problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd91a4",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af81a4c",
   "metadata": {},
   "source": [
    "## Resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd816c",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "\n",
    "\n",
    "## Contents \n",
    "\n",
    "* [What is supervised learning?](#supervised_learning)\n",
    "* [What do supervised learning models do?](#what_SL_do)\n",
    "* [What is regression?](#regression)\n",
    "* [What is classification?](#classification)\n",
    "* [What types of problems does classification solve directly?](#class_solve)\n",
    "    * What types of problems can be reduced to classification?\n",
    "* [What's the difference between two-class and multi-class classification?](#difference)\n",
    "* [Explore Naive Bayes algorithm for classification.](#exploreBayes)\n",
    "    * [Types of probability](#probabilities)\n",
    "    * [Bayes Theorem and Naive Bayes Classifier](#Bayes_Theorem)\n",
    "    * [Assumptions of the modeling function](#assumptions)\n",
    "    * [Implement the algorithm from scratch](#from_scratch)\n",
    "    * [Description of the process](#description)\n",
    "* [Select or generate a small dataset, suitable for classification. Run your algorithm as a sanity check](#small_dataset)\n",
    "* [What is a confusion matrix?](#confusion_matrix)\n",
    "* [What metrics are used to score a classifier?](#score)\n",
    "    * Accuracy, Precision, Recall, others...\n",
    "    * [ROC curve, AUC, interpretation](#ROC)\n",
    "* [Improve the model](#improve)\n",
    "* [Iris Flower Species Case Study](#Iris)\n",
    "    * Explore it to get acquainted with what information it contains\n",
    "    * [Clean up the data](#clean)\n",
    "    * [Perform classification](#do_classification)\n",
    "    * [Score your classification model](#score_model)\n",
    "    * [perform cross-validation](#cross-validation)\n",
    "    * [Use classifier to predict](#predict)\n",
    "        * Split the data into training and testing set\n",
    "    * [Compare your implementation to another one, e.g. `scikit-learn`. They should give the same (or very similar) results](#compare)\n",
    "    * Communicate the results on your dataset\n",
    "    * Optionally, publish your model on the Internet as a Web API\n",
    "    \n",
    "    \n",
    "* [Reference and Links](#reference_and_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3a599",
   "metadata": {},
   "source": [
    "<a id='reference_and_links'></a>\n",
    "[TOP](#top)\n",
    "    \n",
    "\n",
    "## Reference and Links\n",
    "Python Machine Learning (Third Edition) by Sebastian Raschka,Vahid Mirjalili <br>\n",
    "[Supervised learning (Wikipedia)](https://en.wikipedia.org/wiki/Supervised_learning) <br>\n",
    "https://www.investopedia.com/ <br>\n",
    "https://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1 <br>\n",
    "https://mlpy.sourceforge.net/docs/3.1/lin_class.html <br>\n",
    "https://vitalflux.com/classification-problems-real-world-examples/ <br>\n",
    "https://www.educative.io/answers/what-are-classification-problems <br>\n",
    "[Naive Bayes Classifier From Scratch in Python by Jason Brownlee](https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/) <br>\n",
    "[How to Develop a Naive Bayes Classifier from Scratch in Python\n",
    "by Jason Brownlee](https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm/)<br>\n",
    "[Basic probability: Joint, marginal and conditional probability | Independence](https://www.youtube.com/watch?v=SrEmzdOT65s)<br>\n",
    "[Understanding Confusion Matrix by Sarang Narkhede](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)<br>\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)<br>\n",
    "[How to Remember all these Classification Concepts forever by Jerry An](https://medium.com/swlh/how-to-remember-all-these-classification-concepts-forever-761c065be33)<br>\n",
    "[ROC and AUC, Clearly Explained!](https://www.youtube.com/watch?v=4jRBRDbJemM)<br>\n",
    "[Wikipedia - Confusion_matrix](https://en.wikipedia.org/wiki/Confusion_matrix)<br>\n",
    "[multi-class-f1-score](https://www.baeldung.com/cs/multi-class-f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1d81c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='supervised_learning'></a>\n",
    "[TOP](#top)\n",
    "    \n",
    "    \n",
    "## What is supervised learning?\n",
    "\n",
    "Supervised learning is a subset of Machine Learning that characterizes by the use of labeled data for training the algorithms that classify data or predict outcomes. The main goal in supervised learning is to learn a model from labeled training data* that allows us to make predictions** about unseen or future data. Here, the term \"supervised\" refers to a set of training examples (data inputs) where the desired output signals (labels) are already known. The following figure summarizes a typical supervised learning work-flow, where the labeled training data is passed to a machine learning algorithm for fitting a predictive model that can make predictions on new, unlabeled data inputs: \n",
    "\n",
    "<img src=\"Supervised_learning_flow_chart.png\" style=\"max-height: 230px\" alt=\"flow_chart\" />\n",
    "\n",
    "Supervised learning requires confidence in the labels of the input data. Example would be if a colorblind person labels the colors of a dataset. The Algorithm that learns from this dataset will be able to recognize colors the way colorblind people see them. Thus when we want to predict unlabeled data we might not get what we expect\n",
    "\n",
    "\\* Training data - we can also use the terms: input data, predictors, independent variables or features. <br>\\** The output can be called: prediction, response or dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b061c",
   "metadata": {},
   "source": [
    "\n",
    "<a id='what_SL_do'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## What do supervised learning models do?\n",
    "\n",
    "In short they map feature vectors (inputs) to labels (output).\n",
    "The following steps would describe the SL (Supervised Learning)  \n",
    "\n",
    "1. Determine the type of training examples. Before doing anything else, the user should decide what kind of data is to be used as a training set. In the case of handwriting analysis, for example, this might be a single handwritten character, an entire handwritten word, an entire sentence of handwriting or perhaps a full paragraph of handwriting.\n",
    "2. Gather a training set. The training set needs to be representative of the real-world use of the function. Thus, a set of input objects is gathered and corresponding outputs are also gathered, either from human experts or from measurements.\n",
    "3. Determine the input feature representation of the learned function. The accuracy of the learned function depends strongly on how the input object is represented. Typically, the input object is transformed into a feature vector, which contains a number of features that are descriptive of the object. The number of features should not be too large, because of the curse of dimensionality; but should contain enough information to accurately predict the output.\n",
    "4. Determine the structure of the learned function and corresponding learning algorithm. For example, the engineer may choose to use support-vector machines or decision trees.\n",
    "5. Complete the design. Run the learning algorithm on the gathered training set. Some supervised learning algorithms require the user to determine certain control parameters. These parameters may be adjusted by optimizing performance on a subset (called a validation set) of the training set, or via cross-validation.\n",
    "6. Evaluate the accuracy of the learned function. After parameter adjustment and learning, the performance of the resulting function should be measured on a test set that is separate from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5cb01",
   "metadata": {},
   "source": [
    "\n",
    "<a id='regression'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "\n",
    "## What is regression?\n",
    "\n",
    "Regression is used for predicting continuous outcomes.In regression analysis, we are given a number of predictor (<b>explanatory</b>) variables and a continuous response variable (outcome), and we try to find a relationship between those variables that allows us to predict an outcome.The plot bellow shows linear regression, the word itself can be defined as: Statistical method used to determine the strength and character of the relationship between one dependent variable (usually denoted by Y) and a series of other variables (known as independent variables). \n",
    "<img src='regresion_plot.png' style=\"max-height : 300px\" alt=\"regresion_plot\" />\n",
    "\n",
    "* Example: predict the price of a home in a neighborhood based on the houses and their prices that are currently (or and in the past) on the market. the prediction should be a continues value in the form of a price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee47d82",
   "metadata": {},
   "source": [
    "\n",
    "<a id='classification'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "\n",
    "## What is classification?\n",
    "\n",
    "Classification is used for non-continuous outcomes.We can differentiate regression and classification in the following way: Regression is when we predict quantitative outputs, and classification is when we predict qualitative outputs. These two tasks have a lot in common, and in particular both can be viewed as a task in function approximation.\n",
    "Here we can see a plot of red and blue distribution, where we have a a line that determines which dots to be blue and which red. When a new dot is put on the plot we can determine if we should color it in blue or red.\n",
    "\n",
    "<img src=\"classification.png\" style= \"max-height : 300px\" alt=\"classification_plot\" />\n",
    "\n",
    "* Example: predict if the price of a house is falling in one of the three categories \"cheap\", \"Expensive\", \"Middle-class\" based on the houses and their prices that are currently (or and in the past) on the market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f06c8",
   "metadata": {},
   "source": [
    "\n",
    "<a id='class_solve'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## What types of problems does classification solve directly?\n",
    "\n",
    "Classification models can solve problems where we already have labeled data. \n",
    "\n",
    "Typical examples would be :\n",
    "- Customer behavior prediction: Customers can be classified into different categories based on their buying patterns\n",
    "- Document classification: A multinomial classification model can be trained to classify documents in different categories. \n",
    "- Spam filtering: An algorithm is trained to recognize spam email by learning the characteristics of what constitutes spam vs non-spam email. \n",
    "- Image classification: One of the most popular classification problems is image classification: determining what type of object (or scene) is in a digital image. \n",
    "- Image sentiment analysis: Machine learning binary classification models can be built based on machine learning algorithms to classify whether the image contains a positive or negative emotion/sentiment or not. \n",
    "- Customer churn prediction: A binary classification model can be used to classify whether a customer will churn or not in the near future. \n",
    "- Sentiment analysis: A machine learning binary classification model can be trained to identify the sentiment (positive/negative) of a given text document based on classification algorithms \n",
    "\n",
    "### What types of problems can be reduced to classification?\n",
    "Decision making can be reduced to classification. One example would be for an autonomous vehicle to decide if acceleration or break should be used to avoid an accident. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9d346",
   "metadata": {},
   "source": [
    "\n",
    "<a id='difference'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## What's the difference between two-class and multi-class classification?\n",
    "\n",
    "We have the following types classification:\n",
    "- <b>Binary classification</b>: Classifies data into two classes such as Yes / No, good/bad, high/low, suffers from a particular disease or not, etc. The picture below represents classification model representing the lines separating two different classes. Depending upon the type of problems and linear / non-linear data, the boundary separating the classes would be of different nature.<br>\n",
    "Algorithms that are designed for binary classification can be adapted for use for multi-class problems.\n",
    "This involves using a strategy of fitting multiple binary classification models for each class vs. all other classes (called one-vs-rest) or one model for each pair of classes (called one-vs-one).\n",
    "<br><br>\n",
    "- <b>Multi-Class Classification</b>: Classifies data into three or more classes; Document classification, product categorization, malware classification\n",
    "    - The data is classified as hard assignments in one of the categories or classes\n",
    "    - The data is classified as soft assignments, e.g., the probability that each category or class applies to the data.\n",
    "- <b>Multi-Label Classification</b>: The classification problems in which an object can belong to multiple classes.\n",
    "- <b>Imbalanced Classification</b>: The classification problems in which the number of objects in the classes is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ece9c2",
   "metadata": {},
   "source": [
    "\n",
    "<a id='exploreBayes'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## Explore Naive Bayes algorithm for classification.\n",
    "\n",
    "There are many algorithms that can be used for classification and usually we would choose the correct one based on the data and how is it distributed.\n",
    "some examples are:\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Support Vector Machine (SVM)\n",
    "* K-Nearest Neighbour (KNN)\n",
    "* Naive Bayes\n",
    "\n",
    "Lets explore Naive Bayes.\n",
    "Naive Bayes is based on Bayes’ Theorem — an approach to calculate conditional probability based on prior knowledge, and the <b>naive</b> assumption that each feature is independent to each other. The biggest advantage of Naive Bayes is that, while most machine learning algorithms rely on large amount of training data, it performs relatively well even when the training data size is small. Gaussian Naive Bayes is a type of Naive Bayes classifier that follows the normal distribution.\n",
    "<img src=\"Naive_Bayes.png\" style=\"max-height : 200px\" alt=\"Naive_Bayes\" />\n",
    "\n",
    "<a id='probabilities'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "### Types of probability\n",
    "Lets first get some understanding about the Bayes Theorem and some definitions:\n",
    "* <b>Joint Probability of Two Variables</b>: The probability of two <b>simultaneous</b> events:<br>\n",
    "P(A and B) = P(A given B) * P(B)<br>\n",
    "P(A, B)<br>\n",
    "Here, P(A given B) is the probability of event A given that event B has occurred, called the conditional probability<br>\n",
    "The joint probability is symmetrical, meaning that P(A and B) is the same as P(B and A). The calculation using the conditional probability is also symmetrical, for example:<br>\n",
    "P(A and B) = P(A given B) * P(B) = P(B given A) * P(A)<br>\n",
    "<b>Marginal Probability</b>: The probability of an event for one random variable, irrespective of the outcome of another random variable<br>\n",
    "P(X=A) = sum P(X=A, Y=$y_i$) for all y <br>\n",
    "\n",
    "* <b>Conditional Probability</b>:  The probability of an event given the occurrence of another event<br>\n",
    "P(A given B) = P(A and B) / P(B)<br>\n",
    "P(A | B) = P(A,B)/P(B)<br>\n",
    "The conditional probability is not symmetrical, for example: P(A | B) != P(B | A)\n",
    "\n",
    "Example:\n",
    "we have a group of 500 people and we ask for their favorite fruit juice in alcohol. We have the following results:\n",
    "\n",
    "fruit|male|female|TOTAL|\n",
    "-----|---|---|---|\n",
    "Tomato|80|120|200|\n",
    "Pineapple|100|25|125|\n",
    "Other|50|125|175|\n",
    "TOTAL|230|270|500|\n",
    "\n",
    "as we want to work with probabilities we will divide all values to the TOTAL of 500:<br>\n",
    "\n",
    "fruit|male|female|TOTAL|\n",
    "-----|---|---|---|\n",
    "Tomato|0.16|0.24|0.4|\n",
    "Pineapple|0.2|0.05|0.25|\n",
    "Other|0.1|0.25|0.35|\n",
    "TOTAL|0.46|0.54|1|\n",
    "\n",
    "lets answer some questions:<br>\n",
    "What is the probability for a person from this group to be male? => <b>Marginal Probability</b> = 0.46<br>\n",
    "What is the probability for a person from this group to be male and prefer Tomato juice? => <b>Joint Probability</b> = 0.16<br><br>\n",
    "What is the probability for a person from this group to be male <b>OR</b> prefer Tomato juice? Those are all cells in blue.<br>\n",
    "\n",
    "fruit|male|female|TOTAL|\n",
    "-----|---|---|---|\n",
    "Tomato|<b><span style=\"color:blue\">0.16</span></b>|<b><span style=\"color:blue\">0.24</span></b>|0.4|\n",
    "Pineapple|<b><span style=\"color:blue\">0.2</span></b>|0.05|0.25|\n",
    "Other|<b><span style=\"color:blue\">0.1</span></b>|0.25|0.35|\n",
    "TOTAL|0.46|0.54|1|\n",
    "\n",
    "or to put it another way : P(Male or Tomato)=P(Male)+P(Tomato)- P(Male and Tomato)=0.4+0.46-0.16=0.7\n",
    "\n",
    "Now if we ask Anna who is not in the group, what is her favorite juice, what is the probability the answer to be Pineapple?<br>\n",
    "P(Pineapple|Female) , Female is our condition because we know Anna is female. Thus we can focus only on the female column. Lets redo the table for women only<br>\n",
    "\n",
    "fruit|female|%|\n",
    "-----|---|---|\n",
    "Tomato|120|0.444|\n",
    "Pineapple|<b><span style=\"color:orange\">25</span></b>|<b><span style=\"color:orange\">0.093</span></b>|\n",
    "Other|125|0.463|\n",
    "TOTAL|270|1|\n",
    "\n",
    "the Original formula states: P(Pineapple|Female) = P(Pineapples and Female)/P(Female) =0.05/0.54=0.093\n",
    "<br>\n",
    "We can see we get the same result for <b>Conditional Probability</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d428c0",
   "metadata": {},
   "source": [
    "\n",
    "<a id='Bayes_Theorem'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "\n",
    "### Bayes Theorem and Naive Bayes Classifier\n",
    "An Alternate Way To Calculate Conditional Probability <br>\n",
    "There is another way to calculate the conditional probability. Specifically, one conditional probability can be calculated using the other conditional probability; for example:<br>\n",
    "P(A|B) = P(B|A) * P(A) / P(B)<br>\n",
    "The reverse is also true; for example: P(B|A) = P(A|B) * P(B) / P(A)\n",
    "\n",
    "Principled way of calculating a conditional probability without the joint probability.\n",
    "It is often the case that we do not have access to the denominator directly, e.g. P(B).\n",
    "\n",
    "We can calculate it an alternative way; for example:\n",
    "\n",
    "<b>P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)</b>\n",
    "<br>This gives a formulation of Bayes Theorem that we can use that uses the alternate calculation of P(B), described below:\n",
    "\n",
    "<b>P(A|B) = P(B|A) * P(A) / P(B|A) * P(A) + P(B|not A) * P(not A)</b>\n",
    "<br>Or with brackets around the denominator for clarity:\n",
    "\n",
    "<b>P(A|B) = P(B|A) * P(A) / (P(B|A) * P(A) + P(B|not A) * P(not A))</b>\n",
    "<br>Note: the denominator is simply the expansion we gave above.\n",
    "\n",
    "As such, if we have P(A), then we can calculate P(not A) as its complement; for example:\n",
    "\n",
    "<b>P(not A) = 1 – P(A)</b>\n",
    "<br>Additionally, if we have P(not B|not A), then we can calculate P(B|not A) as its complement; for example:\n",
    "\n",
    "<b>P(B|not A) = 1 – P(not B|not A)</b>\n",
    "<br>Now that we are familiar with the calculation of Bayes Theorem, let’s take a closer look at the meaning of the terms in the equation.\n",
    "\n",
    "P(A|B): Posterior probability, Likelihood.<br>\n",
    "P(A): Prior probability, Evidence<br>\n",
    "Posterior = Likelihood * Prior / Evidence\n",
    "\n",
    "What is the probability that there is fire given that there is smoke?<br>\n",
    "Where P(Fire) is the Prior, P(Smoke|Fire) is the Likelihood, and P(Smoke) is the evidence: <b>P(Fire|Smoke) = P(Smoke|Fire) * P(Fire) / P(Smoke)</b>\n",
    "\n",
    "#### Bayes Theorem for Classification\n",
    "Classification is a predictive modeling problem that involves assigning a label to a given input data sample.\n",
    "\n",
    "The problem of classification predictive modeling can be framed as calculating the conditional probability of a class label given a data sample, for example:\n",
    "\n",
    "<b>P(class|data) = (P(data|class) * P(class)) / P(data)</b><br>\n",
    "Where P(class|data) is the probability of class given the provided data.\n",
    "\n",
    "This calculation can be performed for each class in the problem and the class that is assigned the largest probability can be selected and assigned to the input data.\n",
    "\n",
    "In practice, it is very challenging to calculate full Bayes Theorem for classification.\n",
    "\n",
    "The priors for the class and the data are easy to estimate from a training dataset, if the dataset is suitability representative of the broader problem.\n",
    "\n",
    "The conditional probability of the observation based on the class P(data|class) is not feasible unless the number of examples is extraordinarily large, e.g. large enough to effectively estimate the probability distribution for all different possible combinations of values. This is almost never the case, we will not have sufficient coverage of the domain.\n",
    "\n",
    "As such, the direct application of Bayes Theorem also becomes intractable, especially as the number of variables or features (n) increases.\n",
    "\n",
    "\n",
    "#### Naive Bayes Classifier\n",
    "The solution to using Bayes Theorem for a conditional probability classification model is to simplify the calculation.\n",
    "\n",
    "The Bayes Theorem assumes that each input variable is dependent upon all other variables. This is a cause of complexity in the calculation. We can remove this assumption and consider each input variable as being independent from each other.\n",
    "\n",
    "This changes the model from a dependent conditional probability model to an independent conditional probability model and dramatically simplifies the calculation.\n",
    "\n",
    "This means that we calculate P(data|class) for each input variable separately and multiple the results together, for example:\n",
    "\n",
    "<b>P(class | X1, X2, …, Xn) = P(X1|class) * P(X2|class) * … * P(Xn|class) * P(class) / P(data)</b><br>\n",
    "We can also drop the probability of observing the data as it is a constant for all calculations, for example:\n",
    "\n",
    "<b>P(class | X1, X2, …, Xn) = P(X1|class) * P(X2|class) * … * P(Xn|class) * P(class)</b><br>\n",
    "This simplification of Bayes Theorem is common and widely used for classification predictive modeling problems and is generally referred to as Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4e112",
   "metadata": {},
   "source": [
    "\n",
    "<a id='assumptions'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "### Assumptions of the modeling function\n",
    "\n",
    "Naive Bayes is a classification algorithm for binary (two-class) and multi-class classification problems. It is called Naive Bayes or idiot Bayes because the calculations of the probabilities for each class are simplified to make their calculations tractable.\n",
    "\n",
    "* Rather than attempting to calculate the probabilities of each attribute value, they are assumed to be conditionally independent given the class value.\n",
    "\n",
    "This is a very strong assumption that is most unlikely in real data, i.e. that the attributes do not interact. Nevertheless, the approach performs surprisingly well on data where this assumption does not hold.\n",
    "\n",
    "* We will assume the last column in each row is the class value.\n",
    "* We will assume the columns represent the features/independent variables\n",
    "* We will assume the rows represent the individual experiments/entries of the data\n",
    "* We will assume Gaussian Probability Distribution for the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e6778",
   "metadata": {},
   "source": [
    "\n",
    "<a id='from_scratch'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "### Implement the algorithm from scratch\n",
    "\n",
    "This Naive Bayes algorithm can be broken down into 5 parts:\n",
    "\n",
    "[Step 1: Separate By Class.](#step1)<br>\n",
    "[Step 2: Summarize Dataset.](#step2)<br>\n",
    "[Step 3: Summarize Data By Class.](#step3)<br>\n",
    "[Step 4: Gaussian Probability Density Function.](#step4)<br>\n",
    "[Step 5: Class Probabilities.](#step5)<br>\n",
    "\n",
    "#### Step 1: Separate By Class <a id='step1'></a>\n",
    "We will need to calculate the probability of data by the class they belong to, the so-called base rate.\n",
    "\n",
    "This means that we will first need to separate our training data by class.We can create a dictionary object where each key is the class value and then add a list of all the records as the value in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39678ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[-1]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e4088",
   "metadata": {},
   "source": [
    "[List of steps ](#from_scratch)\n",
    "<a id='step2'></a>\n",
    "#### Step 2: Summarize Dataset \n",
    "\n",
    "We need two statistics from a given set of data.\n",
    "\n",
    "The two statistics we require from a given dataset are the mean and the standard deviation (average deviation from the mean).\n",
    "\n",
    "The mean is the average value and can be calculated as:\n",
    "\n",
    "mean: $\\mu = {\\sum_{ i=1}^{N}x_i\\over N}$\n",
    "\n",
    "Where x is the list of values or a column we are looking.\n",
    "The sample standard deviation is calculated as the mean difference from the mean value. This can be calculated as:\n",
    "\n",
    "standard deviation: $std = \\sqrt{\\sum_{ i=1}^{N} (x_i – \\mu)^2 \\over N-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc2366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366368a",
   "metadata": {},
   "source": [
    "We require the mean and standard deviation statistics to be calculated for each input attribute or each column of our data.\n",
    "\n",
    "We can do that by gathering all of the values for each column into a list and calculating the mean and standard deviation on that list. Once calculated, we can gather the statistics together into a list or tuple of statistics. Then, repeat this operation for each column in the dataset and return a list of tuples of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51d9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1])\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98285ab",
   "metadata": {},
   "source": [
    "The zip() function that will aggregate elements from each provided argument. We pass in the dataset to the zip() function with the * operator that separates the dataset (that is a list of lists) into separate lists for each row. The zip() function then iterates over each element of each row and returns a column from the dataset as a list of numbers. \n",
    "\n",
    "We then calculate the mean, standard deviation and count of rows in each column. A tuple is created from these 3 numbers and a list of these tuples is stored. We then remove the statistics for the class variable as we will not need these statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8213d3c",
   "metadata": {},
   "source": [
    "[List of steps ](#from_scratch)\n",
    "<a id='step3'></a>\n",
    "#### Step 3: Summarize Data By Class\n",
    "\n",
    "Below is a function named summarize_by_class() that summarize the columns in the dataset organized by class values. The dataset is first split by class, then statistics are calculated on each subset. The results in the form of a list of tuples of statistics are then stored in a dictionary by their class value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b10aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset by class then calculate statistics for each row\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = dict()\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8338d2f",
   "metadata": {},
   "source": [
    "[List of steps ](#from_scratch)\n",
    "<a id='step4'></a>\n",
    "#### Step 4: Gaussian Probability Density Function\n",
    "\n",
    "Calculating the probability or likelihood of observing a given real-value like $X_1$ is difficult.\n",
    "\n",
    "One way we can do this is to assume that $X_1$ values are drawn from a distribution, such as a bell curve or Gaussian distribution.\n",
    "\n",
    "A Gaussian distribution can be summarized using only two numbers:the mean and the standard deviation. <br>\n",
    "Therefore, with a little math, we can estimate the probability of a given value. This piece of math is called a Gaussian Probability Distribution Function (or Gaussian PDF) and can be calculated as:\n",
    "\n",
    "\n",
    "$$f_{(x)}={1 \\over \\sigma\\sqrt{2\\pi}}e^{-{1 \\over 2}({x-\\mu \\over \\sigma})^2} $$\n",
    "\n",
    "Where $\\sigma$ is the standard deviation for $x$, $\\mu$ is the mean for $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c5a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61fca4",
   "metadata": {},
   "source": [
    "[List of steps ](#from_scratch)\n",
    "<a id='step5'></a>\n",
    "#### Step 5: Class Probabilities\n",
    "\n",
    "Lets use the statistics calculated from our training data to calculate probabilities for new data.\n",
    "\n",
    "Probabilities are calculated separately for each class. This means that we first calculate the probability that a new piece of data belongs to the first class, then calculate probabilities that it belongs to the second class, and so on for all the classes.\n",
    "\n",
    "The probability that a piece of data belongs to a class is calculated as follows:\n",
    "\n",
    "<b>P(class|data) = P(X|class) * P(class)</b><br>\n",
    "You may note that this is different from the Bayes Theorem described above.\n",
    "\n",
    "The division has been removed to simplify the calculation.\n",
    "\n",
    "This means that the result is no longer strictly a probability of the data belonging to a class. The value is still maximized, meaning that the calculation for the class that results in the largest value is taken as the prediction. This is a common implementation simplification as we are often more interested in the class prediction rather than the probability.\n",
    "\n",
    "The input variables are treated separately, giving the technique it’s name “naive“. For example where we have 2 input independent variables/features, the calculation of the probability that a row belongs to the first class 0 can be calculated as:\n",
    "\n",
    "<b>P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)</b><br>\n",
    "Now you can see why we need to separate the data by class value. The Gaussian Probability Density function in the previous step is how we calculate the probability of a real value like $X_1$ and the statistics we prepared are used in this calculation.\n",
    "\n",
    "\n",
    "First the total number of training records is calculated from the counts stored in the summary statistics. This is used in the calculation of the probability of a given class or P(class) as the ratio of rows with a given class of all rows in the training data.\n",
    "\n",
    "Next, probabilities are calculated for each input value in the row using the Gaussian probability density function and the statistics for that column and of that class. Probabilities are multiplied together as they accumulated.\n",
    "\n",
    "This process is repeated for each class in the dataset.\n",
    "\n",
    "Finally a dictionary of probabilities is returned with one entry for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf3ec26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    b=float(0)\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, count = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "            \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555375de",
   "metadata": {},
   "source": [
    "\n",
    "<a id='description'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## Description of the process\n",
    "\n",
    "In simple words, using the labeled data we determine the distribution (assuming in our case a Normal distribution) of the data for each class. then when a new unlabeled data is given we use the created algorithm to check what is the probability for each of the new features to be part of the distribution for each label. then we choose the highest sum and declare this is the predicted label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00675be5",
   "metadata": {},
   "source": [
    "\n",
    "<a id='small_dataset'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## Select or generate a small dataset, suitable for classification. Run your algorithm as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e87ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for our case: {1.0: 0.0690524411081618, 2.0: 5.6625848265616156e-05}\n",
      "The Label is : 1 \n",
      "with probability : 0.0690524411081618\n"
     ]
    }
   ],
   "source": [
    "# Test calculating class probabilities\n",
    "# 2 labes, 1 variables (the last one is the label), n_of_experiments experiments(rows)\n",
    "n_of_experiments = 5000\n",
    "\n",
    "#label 1 [[-10:0],[label=1]]\n",
    "L1 = np.array([np.random.uniform(-10,0,n_of_experiments),[1]*n_of_experiments]).T\n",
    "\n",
    "#label 2 [[-50:-20],[0:10],[1000:1500],[4:7],[label=2]]\n",
    "L2 = np.array([np.random.uniform(-50,-20,n_of_experiments),[2]*n_of_experiments]).T\n",
    "\n",
    "#label 3 [[-30:20],[0:100],[1:150],[0:10],[label=3]]\n",
    "L3 = np.array([np.random.uniform(-30,20,n_of_experiments),np.random.uniform(0,100,n_of_experiments),\n",
    "               np.random.uniform(1,150,n_of_experiments),np.random.uniform(0,10,n_of_experiments),[3]*n_of_experiments]).T\n",
    "\n",
    "dataset = np.concatenate((L1,L2),axis=0) \n",
    "\n",
    "\n",
    "summaries = summarize_by_class(dataset)\n",
    "probabilities = calculate_class_probabilities(summaries, [-5])\n",
    "print(f'Probabilities for our case: {probabilities}')\n",
    "label = [(k,v) for k, v in probabilities.items() if v == max(probabilities.values())]\n",
    "print(f'The Label is : {int(label[0][0])} \\nwith probability : {label[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45c397b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 9.220397762886374e-77, 2.0: 7.450573005484589e-93, 3.0: 1.7398630037082216e-08}\n",
      "The Label is : 3 \n",
      "with probability : 1.7398630037082216e-08\n"
     ]
    }
   ],
   "source": [
    "# Test calculating class probabilities\n",
    "# 3 labes, 5 variables (the last one is the label), n_of_experiments experiments(rows)\n",
    "n_of_experiments = 5000\n",
    "\n",
    "#label 1 [[-10:0],[0:10],[100:150],[0:1],[label=1]]\n",
    "L1 = np.array([np.random.uniform(-10,0,n_of_experiments),np.random.uniform(0,10,n_of_experiments),\n",
    "               np.random.uniform(100,150,n_of_experiments),np.random.uniform(0,1,n_of_experiments),[1]*n_of_experiments]).T\n",
    "\n",
    "#label 2 [[-50:-20],[0:10],[1000:1500],[4:7],[label=2]]\n",
    "L2 = np.array([np.random.uniform(-50,-20,n_of_experiments),np.random.uniform(0,10,n_of_experiments),\n",
    "               np.random.uniform(1000,1500,n_of_experiments),np.random.uniform(4,7,n_of_experiments),[2]*n_of_experiments]).T\n",
    "\n",
    "#label 3 [[-30:20],[0:100],[1:150],[0:10],[label=3]]\n",
    "L3 = np.array([np.random.uniform(-30,20,n_of_experiments),np.random.uniform(0,100,n_of_experiments),\n",
    "               np.random.uniform(1,150,n_of_experiments),np.random.uniform(0,10,n_of_experiments),[3]*n_of_experiments]).T\n",
    "\n",
    "dataset = np.concatenate((L1,L2,L3),axis=0) \n",
    "\n",
    "\n",
    "summaries = summarize_by_class(dataset)\n",
    "probabilities = calculate_class_probabilities(summaries, [-22,55,100,0.2])\n",
    "print(probabilities)\n",
    "label = [(k,v) for k, v in probabilities.items() if v == max(probabilities.values())]\n",
    "print(f'The Label is : {int(label[0][0])} \\nwith probability : {label[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e24a4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7398630037082216e-08"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(probabilities.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69913268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [(-4.952149535254377, 2.8876615118805047, 5000),\n",
       "  (4.953152528229809, 2.9160013456727, 5000),\n",
       "  (124.92207767807997, 14.496451776704312, 5000),\n",
       "  (0.5043315204954785, 0.290172995976334, 5000)],\n",
       " 2.0: [(-34.97987365265758, 8.677781388957923, 5000),\n",
       "  (4.977675411596113, 2.9047939028066985, 5000),\n",
       "  (1252.79273397055, 146.20794232817494, 5000),\n",
       "  (5.491085996562192, 0.8625000223244146, 5000)],\n",
       " 3.0: [(-5.124811212436932, 14.435175883500477, 5000),\n",
       "  (50.10596968337015, 28.81777123565052, 5000),\n",
       "  (75.93752407798421, 43.41389938215305, 5000),\n",
       "  (4.988766221123397, 2.880746761900248, 5000)]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c4701",
   "metadata": {},
   "source": [
    "\n",
    "<a id='confusion_matrix'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## What is a confusion matrix?\n",
    "\n",
    "Confusion Matrix is a performance measurement for machine learning classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values.<br>\n",
    "It is extremely useful for measuring Recall, Precision, Specificity, Accuracy, and most importantly AUC-ROC curves.\n",
    "\n",
    "<img src=\"confusion_matrix.png\" style=\"max-height : 350px\" alt=\"confusion_matrix\" />\n",
    "<p style=\"text-align: center;\">Image by Sarang Narkhede</p>\n",
    "\n",
    "Let’s understand True Positive, False Positive, False Negative, True Negative in terms of pregnancy analogy.\n",
    "\n",
    "<b>True Positive (TP):<br></b>\n",
    "Interpretation: You predicted positive and it’s true.<br>\n",
    "You predicted that a woman is pregnant and she actually is.\n",
    "\n",
    "<b>True Negative (TN):<br></b>\n",
    "Interpretation: You predicted negative and it’s true.<br>\n",
    "You predicted that a man is not pregnant and he actually is not.\n",
    "\n",
    "<b>False Positive (FP): (Type 1 Error)<br></b>\n",
    "Interpretation: You predicted positive and it’s false.<br>\n",
    "You predicted that a man is pregnant but he actually is not.\n",
    "\n",
    "<b>False Negative (FN): (Type 2 Error)<br></b>\n",
    "Interpretation: You predicted negative and it’s false.\n",
    "You predicted that a woman is not pregnant but she actually is.\n",
    "\n",
    "In statistical hypothesis testing, a type I error is the mistaken rejection of an actually true null hypothesis (also known as a \"false positive\" finding or conclusion; example: \"an innocent person is convicted\"), while a type II error is the failure to reject a null hypothesis that is actually false (also known as a \"false negative\" finding or conclusion; example: \"a guilty person is not convicted\").Much of statistical theory revolves around the minimization of one or both of these errors, though the complete elimination of either is a statistical impossibility if the outcome is not determined by a known, observable causal process. By selecting a low threshold (cut-off) value and modifying the alpha ($\\alpha$) level, the quality of the hypothesis test can be increased. The knowledge of type I errors and type II errors is widely used in medical science, biometrics and computer science.\n",
    "\n",
    "<b>Crossover error rate</b>\n",
    "<img src=\"cross_over_err_rate.png\" style=\"max-height : 350px\" alt=\"cross_over_err_rate\" />\n",
    "    <p style=\"text-align: center;\">The results obtained from negative sample (left curve) overlap with the results obtained from positive samples (right curve). By moving the result cutoff value (vertical bar), the rate of false positives (FP) can be decreased, at the cost of raising the number of false negatives (FN), or vice versa (TP = True Positives, TPR = True Positive Rate, FPR = False Positive Rate, TN = True Negatives).</p>\n",
    "    \n",
    "    \n",
    "The Confusion Matrix can have more than 2 rows and columns as shown in the example bellow \n",
    "<img src=\"5d_conf_matrix.png\" style=\"max-height : 150px\" alt=\"5d_conf_matrix\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5b4d4",
   "metadata": {},
   "source": [
    "\n",
    "<a id='score'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## What metrics are used to score a classifier?\n",
    "\n",
    "<img src=\"Confusion matrix - Wikipedia.png\" style=\"max-height : 600px\" alt=\"Confusion matrix - Wikipedia\">\n",
    "\n",
    "\n",
    "\n",
    "### Recall/Sensitivity/TPR(True Positive Rate) \n",
    "Should be high as possible.<br>\n",
    "From all the positive classes, how many we predicted correctly.\n",
    "$$Recall = {TP \\over TP+FN}$$\n",
    "\n",
    "### Specificity/TNR(True Negative Rate )\n",
    "Should be high as possible.<br>\n",
    "Specificity is the proportion of the total number of the actual negative that were identified correctly. The actual negative include situations of true negatives and false positives. It is also known as the true negative rate (TNR)\n",
    "$$Specificity = {TN \\over TN+FP}$$\n",
    "\n",
    "### False Positive Rate(FPR) \n",
    "should be low.\n",
    "$$FPR = {FP \\over TN+FP}$$\n",
    "\n",
    "### False Negative Rate(FNR) \n",
    "should be low.\n",
    "$$FNR = {FN \\over TP+FN}$$\n",
    "\n",
    "### Precision (PPV)\n",
    "From all the classes we have predicted as positive, how many are actually positive.\n",
    "Precision should be high as possible.\n",
    "$$Precision = {TP \\over TP+FP}$$\n",
    "\n",
    "### Accuracy\n",
    "From all the classes (positive and negative), how many of them we have predicted correctly.\n",
    "Accuracy should be high as possible.\n",
    "$$Accuracy = {TP+TN \\over TP+TN+FP+FN}$$\n",
    "Accuracy Fails for Imbalanced Classification\n",
    "\n",
    "\n",
    "### The trade-off of Recall and Precision\n",
    "There is a trade-off between recall and precision. It shows how the recall vs precision relationship changes as we vary the threshold for identifying a positive in our model.<br>\n",
    "When we increase the recall rate by adjusting the classification threshold of a model, the precision rate is decreased.\n",
    "\n",
    "<img src=\"prec_recall_tradeoff.png\" style=\"max-height : 300px\" alt=\"prec_recall_tradeoff\">\n",
    "\n",
    "Because high precision and high recall are what every model optimizes for. Consider the tradeoff, there is a balancing metric called F1 score that combines the two terms.\n",
    "* F-measure - It is difficult to compare two models with low precision and high recall or vice versa. So to make them comparable, we use F-Score. F-score helps to measure Recall and Precision at the same time. It uses Harmonic Mean in place of Arithmetic Mean by punishing the extreme values more.\n",
    "$$F-measure = {2*Recall*Precision \\over Recall+Precision} = {2TP \\over 2TP+FP+FN}$$\n",
    "\n",
    "$F_\\beta$ score - more general F score that uses a positive real factor $\\beta$ where $\\beta$ is chosen such that recall is considered $\\beta$ times as important as precision, is: $$F_\\beta = (1+\\beta^2){precision*recall \\over \\beta^2*prscision+recall} $$\n",
    "\n",
    "$$F_\\beta = (1+\\beta^2){(1+\\beta^2)TP \\over (1+\\beta^2)TP+\\beta^2FN+FP} $$\n",
    "\n",
    "Two commonly used values for $\\beta$ are 2, which weighs recall higher than precision, and 0.5, which weighs recall lower than precision.\n",
    "\n",
    "The F-measure was derived so that $F_\\beta$ \"measures the effectiveness of retrieval with respect to a user who attaches \n",
    "$\\beta$ times as much importance to recall as precision\". It is based on Van Rijsbergen's effectiveness measure.\n",
    "\n",
    "\n",
    "<b>Cohen’s Kappa Score</b>\n",
    "<img src=\"cohen_kappa.png\" style=\"max-height : 300px\" alt=\"cohen_kappa\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8ed22",
   "metadata": {},
   "source": [
    "\n",
    "<a id='ROC'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "### ROC Curve, AUC, interpretation\n",
    "A ROC (receiver operating characteristic) curve plots the true positive rate on the y-axis versus the false positive rate on the x-axis. It shows the true positive and false positive rate for every probability threshold of a binary classifier. the ROC heps us decide what threshold to choose!\n",
    "for example if it is very important to identify all True measurements as Positive (TPR= 1) then we might have to lower the threshold! \n",
    "\n",
    "<img src=\"ROC_curve.png\" style=\"max-height : 300px\" alt=\"ROC_curve\">\n",
    "<img src=\"ROC_curve_legend.png\" style=\"max-height : 200px\" alt=\"ROC_curve_legend\">\n",
    "\n",
    "\n",
    "\n",
    "<b>AUC (Area Under the ROC Curve)</b> - AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus). AUC helps us compare ROC curves. the larger the Area of AUC the better the ROC curve.<br>\n",
    "<br>\n",
    "<br>\n",
    "The higher the AUC the better the model, then when we are satisfied with our model based on the ROC  and the context of our research we can choose the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f7298",
   "metadata": {},
   "source": [
    "\n",
    "<a id='improve'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## Improve the model\n",
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "\n",
    "Extensions\n",
    "This section lists extensions to the tutorial that you may wish to explore.\n",
    "\n",
    "Log Probabilities: The conditional probabilities for each class given an attribute value are small. When they are multiplied together they result in very small values, which can lead to floating point underflow (numbers too small to represent in Python). A common fix for this is to add the log of the probabilities together. Research and implement this improvement.\n",
    "Nominal Attributes: Update the implementation to support nominal attributes. This is much similar and the summary information you can collect for each attribute is the ratio of category values for each class. Dive into the references for more information.\n",
    "Different Density Function (bernoulli or multinomial): We have looked at Gaussian Naive Bayes, but you can also look at other distributions. Implement a different distribution such as multinomial, bernoulli or kernel naive bayes that make different assumptions about the distribution of attribute values and/or their relationship with the class value.\n",
    "If you try any of these extensions, let me know in the comments below.\n",
    "\n",
    "https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3237a69",
   "metadata": {},
   "source": [
    "\n",
    "<a id='Iris'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "## Iris Flower Species Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61f970",
   "metadata": {},
   "source": [
    "\n",
    "<a id='clean'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "#### Clean up the data\n",
    "We will make sure the columns are represented with a float numbers.\n",
    "We will also set numerical categories for the plants names. Creating a dictionary  so that we can identify then later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45cb20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15406d",
   "metadata": {},
   "source": [
    "\n",
    "<a id='do_classification'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "#### Perform classification\n",
    "\n",
    "first we will load the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0633f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204c8ee",
   "metadata": {},
   "source": [
    "and then we can fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df16de03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [(-4.952149535254377, 2.8876615118805047, 5000),\n",
       "  (4.953152528229809, 2.9160013456727, 5000),\n",
       "  (124.92207767807997, 14.496451776704312, 5000),\n",
       "  (0.5043315204954785, 0.290172995976334, 5000)],\n",
       " 2.0: [(-34.97987365265758, 8.677781388957923, 5000),\n",
       "  (4.977675411596113, 2.9047939028066985, 5000),\n",
       "  (1252.79273397055, 146.20794232817494, 5000),\n",
       "  (5.491085996562192, 0.8625000223244146, 5000)],\n",
       " 3.0: [(-5.124811212436932, 14.435175883500477, 5000),\n",
       "  (50.10596968337015, 28.81777123565052, 5000),\n",
       "  (75.93752407798421, 43.41389938215305, 5000),\n",
       "  (4.988766221123397, 2.880746761900248, 5000)]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model = summarize_by_class(dataset)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e88ea983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for a given row\n",
    "def predict(summaries, row):\n",
    "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
    "\tbest_label, best_prob = None, -1\n",
    "\tfor class_value, probability in probabilities.items():\n",
    "\t\tif best_label is None or probability > best_prob:\n",
    "\t\t\tbest_prob = probability\n",
    "\t\t\tbest_label = class_value\n",
    "\treturn best_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42d6b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
      "Data=[5.7, 2.9, 4.2, 1.3], Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "legend = str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# fit model\n",
    "model = summarize_by_class(dataset)\n",
    "# define a new record\n",
    "row = [5.7,2.9,4.2,1.3]\n",
    "# predict the label\n",
    "label = predict(model, row)\n",
    "print(legend)\n",
    "print('Data=%s, Predicted: %s' % (row, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01475542",
   "metadata": {},
   "source": [
    "\n",
    "<a id='score_model'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "#### Score your classification model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7f728720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, dataset):\n",
    "    ROC_table = np.zeros((3,3))\n",
    "    for i in dataset:\n",
    "        label_p = int(predict(model,i))\n",
    "        label_r = int(i[4])\n",
    "        ROC_table[label_p, label_r]+=1\n",
    "    row_names = [\"Predicted_1\", \"Predicted_2\", \"Predicted_3\"]\n",
    "    column_names = [\"Real_1\", \"Real_2\", \"Real_3\"]\n",
    "    roc_my_code = pd.DataFrame(ROC_table, index=row_names, columns=column_names)\n",
    "    return roc_my_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d6a91a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real_1</th>\n",
       "      <th>Real_2</th>\n",
       "      <th>Real_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted_1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Real_1  Real_2  Real_3\n",
       "Predicted_1    50.0     0.0     0.0\n",
       "Predicted_2     0.0    47.0     3.0\n",
       "Predicted_3     0.0     3.0    47.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=score_model(model, dataset)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10c2dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class_1: \n",
      " Precision: 1.0\n",
      " Recall: 1.0 \n",
      "\n",
      "Class_2: \n",
      " Precision: 0.94\n",
      " Recall: 0.94 \n",
      "\n",
      "Class_3: \n",
      " Precision: 0.94\n",
      " Recall: 0.94 \n",
      "\n",
      "\n",
      "F1_class_1: 1.0\n",
      "F1_class_2: 0.94\n",
      "F1_class_3: 0.94\n"
     ]
    }
   ],
   "source": [
    "Precision_1 = ROC_table[0,0]/sum(ROC_table[0,0:])\n",
    "Precision_2 = ROC_table[1,1]/sum(ROC_table[1,0:])\n",
    "Precision_3 = ROC_table[2,2]/sum(ROC_table[2,0:])\n",
    "Recall_1 = ROC_table[0,0]/sum(ROC_table[0:,0])\n",
    "Recall_2 = ROC_table[1,1]/sum(ROC_table[0:,1])\n",
    "Recall_3 = ROC_table[2,2]/sum(ROC_table[0:,2])\n",
    "print(f'Class_1: \\n Precision: {Precision_1}\\n Recall: {Recall_1} \\n\\nClass_2: \\n Precision: {Precision_2}\\n Recall: {Recall_2} \\n\\nClass_3: \\n Precision: {Precision_3}\\n Recall: {Recall_3} \\n\\n')\n",
    "print(f'F1_class_1: {2*Precision_1*Recall_1/(Precision_1+Recall_1)}')\n",
    "print(f'F1_class_2: {2*Precision_2*Recall_2/(Precision_2+Recall_2)}')\n",
    "print(f'F1_class_3: {2*Precision_3*Recall_3/(Precision_3+Recall_3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5303b2",
   "metadata": {},
   "source": [
    "\n",
    "<a id='cross-validation'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "#### perform cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "032d5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor _ in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18e9f63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 93.33333333333333]\n",
      "Mean Accuracy: 95.33%\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "\tsummarize = summarize_by_class(train)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\toutput = predict(summarize, row)\n",
    "\t\tpredictions.append(output)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Test Naive Bayes on Iris Dataset\n",
    "seed(1)\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.2f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922c336",
   "metadata": {},
   "source": [
    "\n",
    "<a id='predict'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "#### Use classifier to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cf93c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.1, 3.5, 1.4, 0.2, 0],\n",
       " [4.9, 3.0, 1.4, 0.2, 0],\n",
       " [4.7, 3.2, 1.3, 0.2, 0],\n",
       " [4.6, 3.1, 1.5, 0.2, 0],\n",
       " [5.0, 3.6, 1.4, 0.2, 0],\n",
       " [5.4, 3.9, 1.7, 0.4, 0],\n",
       " [4.6, 3.4, 1.4, 0.3, 0],\n",
       " [5.0, 3.4, 1.5, 0.2, 0],\n",
       " [4.4, 2.9, 1.4, 0.2, 0],\n",
       " [4.9, 3.1, 1.5, 0.1, 0],\n",
       " [5.4, 3.7, 1.5, 0.2, 0],\n",
       " [4.8, 3.4, 1.6, 0.2, 0],\n",
       " [4.8, 3.0, 1.4, 0.1, 0],\n",
       " [4.3, 3.0, 1.1, 0.1, 0],\n",
       " [5.8, 4.0, 1.2, 0.2, 0],\n",
       " [5.7, 4.4, 1.5, 0.4, 0],\n",
       " [5.4, 3.9, 1.3, 0.4, 0],\n",
       " [5.1, 3.5, 1.4, 0.3, 0],\n",
       " [5.7, 3.8, 1.7, 0.3, 0],\n",
       " [5.1, 3.8, 1.5, 0.3, 0],\n",
       " [5.4, 3.4, 1.7, 0.2, 0],\n",
       " [5.1, 3.7, 1.5, 0.4, 0],\n",
       " [4.6, 3.6, 1.0, 0.2, 0],\n",
       " [5.1, 3.3, 1.7, 0.5, 0],\n",
       " [4.8, 3.4, 1.9, 0.2, 0],\n",
       " [5.0, 3.0, 1.6, 0.2, 0],\n",
       " [5.0, 3.4, 1.6, 0.4, 0],\n",
       " [5.2, 3.5, 1.5, 0.2, 0],\n",
       " [5.2, 3.4, 1.4, 0.2, 0],\n",
       " [4.7, 3.2, 1.6, 0.2, 0],\n",
       " [4.8, 3.1, 1.6, 0.2, 0],\n",
       " [5.4, 3.4, 1.5, 0.4, 0],\n",
       " [5.2, 4.1, 1.5, 0.1, 0],\n",
       " [5.5, 4.2, 1.4, 0.2, 0],\n",
       " [4.9, 3.1, 1.5, 0.1, 0],\n",
       " [5.0, 3.2, 1.2, 0.2, 0],\n",
       " [5.5, 3.5, 1.3, 0.2, 0],\n",
       " [4.9, 3.1, 1.5, 0.1, 0],\n",
       " [4.4, 3.0, 1.3, 0.2, 0],\n",
       " [5.1, 3.4, 1.5, 0.2, 0]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "100795f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=30\n",
    "trainig_set=np.array(dataset[0:x]+dataset[50:50+x]+dataset[100:100+x])\n",
    "trainig_set.shape\n",
    "test_set=np.array(dataset[x:50]+dataset[50+x:100]+dataset[100+x:150])\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "25808246",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = summarize_by_class(trainig_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "75d0e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2=score_model(model2,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "897d19ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real_1</th>\n",
       "      <th>Real_2</th>\n",
       "      <th>Real_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted_1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Real_1  Real_2  Real_3\n",
       "Predicted_1    20.0     0.0     0.0\n",
       "Predicted_2     0.0    20.0     2.0\n",
       "Predicted_3     0.0     0.0    18.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d9777",
   "metadata": {},
   "source": [
    "\n",
    "<a id='compare'></a>\n",
    "[TOP](#top)\n",
    "\n",
    "#### Compare your implementation to another one, e.g. `scikit-learn`. They should give the same (or very similar) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1d0f8c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 60 points : 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = np.array(dataset)[:,:4]\n",
    "y = np.array(dataset)[:,4]\n",
    "# print(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
